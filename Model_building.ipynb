{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_weighted_average(sentiment_scores, decay_factor):\n",
    "    \"\"\"\n",
    "    Calculate a balanced weighted average of sentiment scores without biasing towards negative values.\n",
    "    \n",
    "    Parameters:\n",
    "    - sentiment_scores: A list or pandas Series of sentiment scores (positive and negative).\n",
    "    - decay_factor: A value between 0 and 1 to control the decay rate of weights; defaults to 0.95.\n",
    "    \n",
    "    Returns:\n",
    "    - A single balanced weighted average score.\n",
    "    \"\"\"\n",
    "    # Initialize positive and negative scores with respective weights\n",
    "    positive_scores = sentiment_scores[sentiment_scores > 0]\n",
    "    negative_scores = sentiment_scores[sentiment_scores < 0]\n",
    "    \n",
    "    # Calculate decay weights for each score in reverse order (older scores get smaller weights)\n",
    "    decay_weights = decay_factor ** np.arange(len(sentiment_scores))[::-1]\n",
    "\n",
    "    # Separate weights for positive and negative scores\n",
    "    pos_weights = decay_weights[:len(positive_scores)]\n",
    "    neg_weights = decay_weights[:len(negative_scores)]\n",
    "\n",
    "    # Calculate the weighted average for positive and negative scores separately\n",
    "    pos_weighted_avg = (positive_scores * pos_weights).sum() / pos_weights.sum() if len(pos_weights) > 0 else 0\n",
    "    neg_weighted_avg = (negative_scores * neg_weights).sum() / neg_weights.sum() if len(neg_weights) > 0 else 0\n",
    "\n",
    "    # Return the balanced average by combining positive and negative averages equally\n",
    "    balanced_avg = (pos_weighted_avg + neg_weighted_avg) / 2\n",
    "\n",
    "    return balanced_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stock_sentiment_sma_changes(stock_symbols, interval_days, decay_factor, start_date, end_date):\n",
    "    # Initialize dictionaries to hold data\n",
    "    df_stock_news_sentiment_scores_dict = {}\n",
    "    df_news_sentiment_scores_dict = {}\n",
    "    df_stock_data_dict = {}\n",
    "    results = {}\n",
    "\n",
    "    # Ensure start_date and end_date are datetime.date objects\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "    if isinstance(end_date, str):\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d').date()\n",
    "\n",
    "    for symbol in stock_symbols:\n",
    "        # Load data and convert date columns to datetime.date\n",
    "        try:\n",
    "            df_stock_news_sentiment_scores_dict[symbol] = pd.read_csv(f'/Users/rishabhbhardwaj/Desktop/Bootcamp project/Sentiment_scores/stock_news_sentiment_scores/stock_news_sentiment_analysis_results_{symbol}.csv')\n",
    "            df_news_sentiment_scores_dict[symbol] = pd.read_csv(f'/Users/rishabhbhardwaj/Desktop/Bootcamp project/Sentiment_scores/news_sentiment_scores/2000-2024/sentiment_analysis_results_{symbol}.csv')\n",
    "            df_stock_data_dict[symbol] = pd.read_csv(f'/Users/rishabhbhardwaj/Desktop/Bootcamp project/stocks data/stock_data_{symbol}.csv')\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error loading data for {symbol}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Rename columns to distinguish sentiment sources\n",
    "        df_news_sentiment_scores_dict[symbol] = df_news_sentiment_scores_dict[symbol].rename(columns={'weighted compound sentiment score': 'weighted compound news sentiment score'})\n",
    "        df_stock_news_sentiment_scores_dict[symbol] = df_stock_news_sentiment_scores_dict[symbol].rename(columns={'weighted compound sentiment score': 'weighted compound stock sentiment score'})\n",
    "\n",
    "        # Convert 'Date' to datetime.date format\n",
    "        for df in [df_stock_news_sentiment_scores_dict[symbol], df_news_sentiment_scores_dict[symbol], df_stock_data_dict[symbol]]:\n",
    "            df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "\n",
    "        # Filter data within date range\n",
    "        filtered_stock_sentiment = df_stock_news_sentiment_scores_dict[symbol][\n",
    "            (df_stock_news_sentiment_scores_dict[symbol]['Date'] >= start_date) & \n",
    "            (df_stock_news_sentiment_scores_dict[symbol]['Date'] <= end_date)\n",
    "        ]\n",
    "        filtered_news_sentiment = df_news_sentiment_scores_dict[symbol][\n",
    "            (df_news_sentiment_scores_dict[symbol]['Date'] >= start_date) & \n",
    "            (df_news_sentiment_scores_dict[symbol]['Date'] <= end_date)\n",
    "        ]\n",
    "        filtered_stock = df_stock_data_dict[symbol][\n",
    "            (df_stock_data_dict[symbol]['Date'] >= start_date) & \n",
    "            (df_stock_data_dict[symbol]['Date'] <= end_date)\n",
    "        ]\n",
    "\n",
    "        # Merge data on 'Date'\n",
    "        merged_data = pd.merge(filtered_news_sentiment, filtered_stock_sentiment, on='Date', how='inner')\n",
    "        merged_data = pd.merge(merged_data, filtered_stock, on='Date', how='inner')\n",
    "        merged_data.sort_values(by='Date', inplace=True)\n",
    "\n",
    "        # Check if data is sufficient\n",
    "        if len(merged_data) < interval_days:\n",
    "            print(f\"Not enough data for {symbol} with interval_days = {interval_days}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Initialize lists to store results\n",
    "        price_diff_list = []\n",
    "        balanced_avg_stock_sentiment_list = []\n",
    "        balanced_avg_news_sentiment_list = []\n",
    "        sma_list = []\n",
    "        date_list = []\n",
    "\n",
    "        # Calculate SMA, price difference, and balanced weighted average sentiment\n",
    "        for i in range(len(merged_data) - interval_days + 1):\n",
    "            date_d = merged_data['Date'].iloc[i + interval_days - 1]\n",
    "\n",
    "            # Calculate price difference\n",
    "            close_d = merged_data['Close'].iloc[i]\n",
    "            close_d_T = merged_data['Close'].iloc[i + interval_days - 1]\n",
    "            price_diff = close_d_T - close_d\n",
    "\n",
    "            # Calculate SMA\n",
    "            sma = merged_data['Close'].iloc[i:i + interval_days].mean()\n",
    "\n",
    "            # Calculate balanced weighted averages for sentiments\n",
    "            news_sentiment_scores = merged_data['weighted compound news sentiment score'].iloc[i:i + interval_days]\n",
    "            stock_sentiment_scores = merged_data['weighted compound stock sentiment score'].iloc[i:i + interval_days]\n",
    "\n",
    "            balanced_avg_stock_sentiment = balanced_weighted_average(stock_sentiment_scores, decay_factor)\n",
    "            balanced_avg_news_sentiment = balanced_weighted_average(news_sentiment_scores, decay_factor)\n",
    "\n",
    "            # Append results\n",
    "            date_list.append(date_d)\n",
    "            price_diff_list.append(price_diff)\n",
    "            sma_list.append(sma)\n",
    "            balanced_avg_stock_sentiment_list.append(balanced_avg_stock_sentiment)\n",
    "            balanced_avg_news_sentiment_list.append(balanced_avg_news_sentiment)\n",
    "\n",
    "        # Store results for the symbol\n",
    "        results[symbol] = pd.DataFrame({\n",
    "            'Date': date_list,\n",
    "            f'{symbol}_Price_Diff_{interval_days}d': price_diff_list,\n",
    "            f'{symbol}_SMA_{interval_days}d': sma_list,\n",
    "            f'{symbol}_Balanced_Avg_Stock_Sentiment_{interval_days}d': balanced_avg_stock_sentiment_list,\n",
    "            f'{symbol}_Balanced_Avg_News_Sentiment_{interval_days}d': balanced_avg_news_sentiment_list\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_symbols = ['GOOG', 'MSFT', 'NVDA','AMZN','AAPL']\n",
    "interval_days = 14\n",
    "decay_factor = 0.60\n",
    "results = compute_stock_sentiment_sma_changes(stock_symbols, interval_days, decay_factor, start_date='2011-05-16', end_date='2024-09-21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>NVDA_Price_Diff_14d</th>\n",
       "      <th>NVDA_SMA_14d</th>\n",
       "      <th>NVDA_Balanced_Avg_Stock_Sentiment_14d</th>\n",
       "      <th>NVDA_Balanced_Avg_News_Sentiment_14d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-24</td>\n",
       "      <td>1.402091</td>\n",
       "      <td>0.610644</td>\n",
       "      <td>0.056799</td>\n",
       "      <td>-0.090017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>2.035604</td>\n",
       "      <td>0.756274</td>\n",
       "      <td>0.068279</td>\n",
       "      <td>-0.042524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>2.343830</td>\n",
       "      <td>0.924198</td>\n",
       "      <td>0.066722</td>\n",
       "      <td>-0.103465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>2.816398</td>\n",
       "      <td>1.122249</td>\n",
       "      <td>0.074453</td>\n",
       "      <td>-0.052518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>3.356416</td>\n",
       "      <td>1.364398</td>\n",
       "      <td>0.079559</td>\n",
       "      <td>-0.097251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>3.811921</td>\n",
       "      <td>1.637301</td>\n",
       "      <td>0.081651</td>\n",
       "      <td>-0.128987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>4.885393</td>\n",
       "      <td>1.993076</td>\n",
       "      <td>0.024940</td>\n",
       "      <td>-0.107629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>5.251381</td>\n",
       "      <td>2.372470</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>-0.060860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>5.456349</td>\n",
       "      <td>2.764122</td>\n",
       "      <td>0.054831</td>\n",
       "      <td>-0.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>4.835690</td>\n",
       "      <td>3.107125</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>-0.060012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>4.950420</td>\n",
       "      <td>3.474627</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.016897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>6.414189</td>\n",
       "      <td>3.931637</td>\n",
       "      <td>-0.008039</td>\n",
       "      <td>0.010564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>8.718942</td>\n",
       "      <td>4.611008</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.019696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>11.458883</td>\n",
       "      <td>5.449037</td>\n",
       "      <td>0.056632</td>\n",
       "      <td>0.060093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>11.836731</td>\n",
       "      <td>6.339998</td>\n",
       "      <td>0.046039</td>\n",
       "      <td>0.102867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>16.477774</td>\n",
       "      <td>7.539506</td>\n",
       "      <td>0.095124</td>\n",
       "      <td>0.065860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-11-10</td>\n",
       "      <td>26.288190</td>\n",
       "      <td>9.447869</td>\n",
       "      <td>0.043153</td>\n",
       "      <td>0.066059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>26.643905</td>\n",
       "      <td>11.391983</td>\n",
       "      <td>0.071347</td>\n",
       "      <td>0.009510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>18.130239</td>\n",
       "      <td>12.720159</td>\n",
       "      <td>0.063357</td>\n",
       "      <td>0.096118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>22.325472</td>\n",
       "      <td>14.398330</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.061546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>5.822131</td>\n",
       "      <td>14.844634</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.009449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>11.172682</td>\n",
       "      <td>15.659236</td>\n",
       "      <td>-0.026493</td>\n",
       "      <td>-0.007447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-02-09</td>\n",
       "      <td>16.991583</td>\n",
       "      <td>16.826184</td>\n",
       "      <td>-0.026493</td>\n",
       "      <td>0.038701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-03-09</td>\n",
       "      <td>17.784503</td>\n",
       "      <td>18.118601</td>\n",
       "      <td>0.016481</td>\n",
       "      <td>0.016628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>15.867003</td>\n",
       "      <td>19.355368</td>\n",
       "      <td>0.029068</td>\n",
       "      <td>0.025863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>17.380754</td>\n",
       "      <td>20.818064</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.060105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>14.537197</td>\n",
       "      <td>22.071684</td>\n",
       "      <td>0.011103</td>\n",
       "      <td>0.040131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>24.939049</td>\n",
       "      <td>23.925514</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.015671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-06-27</td>\n",
       "      <td>22.690680</td>\n",
       "      <td>25.900303</td>\n",
       "      <td>0.066814</td>\n",
       "      <td>-0.028542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-08-03</td>\n",
       "      <td>15.089357</td>\n",
       "      <td>27.709494</td>\n",
       "      <td>0.062790</td>\n",
       "      <td>-0.032704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-09-12</td>\n",
       "      <td>14.518513</td>\n",
       "      <td>28.812916</td>\n",
       "      <td>0.056465</td>\n",
       "      <td>0.003025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>22.479986</td>\n",
       "      <td>29.843669</td>\n",
       "      <td>0.049607</td>\n",
       "      <td>-0.045624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>14.530605</td>\n",
       "      <td>31.264724</td>\n",
       "      <td>0.114584</td>\n",
       "      <td>0.035993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-10-24</td>\n",
       "      <td>32.074375</td>\n",
       "      <td>32.407378</td>\n",
       "      <td>0.042147</td>\n",
       "      <td>-0.032585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>30.338100</td>\n",
       "      <td>34.973121</td>\n",
       "      <td>0.119532</td>\n",
       "      <td>-0.099708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>26.557207</td>\n",
       "      <td>37.238964</td>\n",
       "      <td>0.118767</td>\n",
       "      <td>0.008258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>24.134237</td>\n",
       "      <td>39.041570</td>\n",
       "      <td>0.071105</td>\n",
       "      <td>0.025720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024-01-09</td>\n",
       "      <td>30.173817</td>\n",
       "      <td>41.163288</td>\n",
       "      <td>0.110524</td>\n",
       "      <td>0.046142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>62.669329</td>\n",
       "      <td>45.969007</td>\n",
       "      <td>0.073864</td>\n",
       "      <td>-0.010763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>51.769217</td>\n",
       "      <td>49.678946</td>\n",
       "      <td>0.071620</td>\n",
       "      <td>0.045670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>53.311611</td>\n",
       "      <td>54.302377</td>\n",
       "      <td>0.024703</td>\n",
       "      <td>0.089197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>93.038586</td>\n",
       "      <td>61.141419</td>\n",
       "      <td>0.039486</td>\n",
       "      <td>0.050498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>73.422043</td>\n",
       "      <td>66.574278</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.111181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  NVDA_Price_Diff_14d  NVDA_SMA_14d  \\\n",
       "0   2016-10-24             1.402091      0.610644   \n",
       "1   2016-12-14             2.035604      0.756274   \n",
       "2   2016-12-28             2.343830      0.924198   \n",
       "3   2017-05-11             2.816398      1.122249   \n",
       "4   2017-06-09             3.356416      1.364398   \n",
       "5   2017-08-14             3.811921      1.637301   \n",
       "6   2018-01-05             4.885393      1.993076   \n",
       "7   2018-02-13             5.251381      2.372470   \n",
       "8   2018-03-22             5.456349      2.764122   \n",
       "9   2018-04-09             4.835690      3.107125   \n",
       "10  2018-04-10             4.950420      3.474627   \n",
       "11  2020-03-04             6.414189      3.931637   \n",
       "12  2020-07-08             8.718942      4.611008   \n",
       "13  2020-11-25            11.458883      5.449037   \n",
       "14  2021-05-14            11.836731      6.339998   \n",
       "15  2021-06-24            16.477774      7.539506   \n",
       "16  2021-11-10            26.288190      9.447869   \n",
       "17  2021-11-11            26.643905     11.391983   \n",
       "18  2022-01-25            18.130239     12.720159   \n",
       "19  2022-03-25            22.325472     14.398330   \n",
       "20  2022-10-11             5.822131     14.844634   \n",
       "21  2022-12-08            11.172682     15.659236   \n",
       "22  2023-02-09            16.991583     16.826184   \n",
       "23  2023-03-09            17.784503     18.118601   \n",
       "24  2023-03-13            15.867003     19.355368   \n",
       "25  2023-04-10            17.380754     20.818064   \n",
       "26  2023-04-28            14.537197     22.071684   \n",
       "27  2023-06-05            24.939049     23.925514   \n",
       "28  2023-06-27            22.690680     25.900303   \n",
       "29  2023-08-03            15.089357     27.709494   \n",
       "30  2023-09-12            14.518513     28.812916   \n",
       "31  2023-10-02            22.479986     29.843669   \n",
       "32  2023-10-18            14.530605     31.264724   \n",
       "33  2023-10-24            32.074375     32.407378   \n",
       "34  2023-12-08            30.338100     34.973121   \n",
       "35  2023-12-15            26.557207     37.238964   \n",
       "36  2024-01-03            24.134237     39.041570   \n",
       "37  2024-01-09            30.173817     41.163288   \n",
       "38  2024-03-27            62.669329     45.969007   \n",
       "39  2024-04-22            51.769217     49.678946   \n",
       "40  2024-05-17            53.311611     54.302377   \n",
       "41  2024-07-10            93.038586     61.141419   \n",
       "42  2024-07-19            73.422043     66.574278   \n",
       "\n",
       "    NVDA_Balanced_Avg_Stock_Sentiment_14d  \\\n",
       "0                                0.056799   \n",
       "1                                0.068279   \n",
       "2                                0.066722   \n",
       "3                                0.074453   \n",
       "4                                0.079559   \n",
       "5                                0.081651   \n",
       "6                                0.024940   \n",
       "7                                0.006671   \n",
       "8                                0.054831   \n",
       "9                                0.024221   \n",
       "10                               0.013566   \n",
       "11                              -0.008039   \n",
       "12                               0.002253   \n",
       "13                               0.056632   \n",
       "14                               0.046039   \n",
       "15                               0.095124   \n",
       "16                               0.043153   \n",
       "17                               0.071347   \n",
       "18                               0.063357   \n",
       "19                               0.002659   \n",
       "20                               0.002989   \n",
       "21                              -0.026493   \n",
       "22                              -0.026493   \n",
       "23                               0.016481   \n",
       "24                               0.029068   \n",
       "25                               0.011700   \n",
       "26                               0.011103   \n",
       "27                               0.008274   \n",
       "28                               0.066814   \n",
       "29                               0.062790   \n",
       "30                               0.056465   \n",
       "31                               0.049607   \n",
       "32                               0.114584   \n",
       "33                               0.042147   \n",
       "34                               0.119532   \n",
       "35                               0.118767   \n",
       "36                               0.071105   \n",
       "37                               0.110524   \n",
       "38                               0.073864   \n",
       "39                               0.071620   \n",
       "40                               0.024703   \n",
       "41                               0.039486   \n",
       "42                               0.003921   \n",
       "\n",
       "    NVDA_Balanced_Avg_News_Sentiment_14d  \n",
       "0                              -0.090017  \n",
       "1                              -0.042524  \n",
       "2                              -0.103465  \n",
       "3                              -0.052518  \n",
       "4                              -0.097251  \n",
       "5                              -0.128987  \n",
       "6                              -0.107629  \n",
       "7                              -0.060860  \n",
       "8                              -0.074000  \n",
       "9                              -0.060012  \n",
       "10                              0.016897  \n",
       "11                              0.010564  \n",
       "12                              0.019696  \n",
       "13                              0.060093  \n",
       "14                              0.102867  \n",
       "15                              0.065860  \n",
       "16                              0.066059  \n",
       "17                              0.009510  \n",
       "18                              0.096118  \n",
       "19                              0.061546  \n",
       "20                              0.009449  \n",
       "21                             -0.007447  \n",
       "22                              0.038701  \n",
       "23                              0.016628  \n",
       "24                              0.025863  \n",
       "25                              0.060105  \n",
       "26                              0.040131  \n",
       "27                             -0.015671  \n",
       "28                             -0.028542  \n",
       "29                             -0.032704  \n",
       "30                              0.003025  \n",
       "31                             -0.045624  \n",
       "32                              0.035993  \n",
       "33                             -0.032585  \n",
       "34                             -0.099708  \n",
       "35                              0.008258  \n",
       "36                              0.025720  \n",
       "37                              0.046142  \n",
       "38                             -0.010763  \n",
       "39                              0.045670  \n",
       "40                              0.089197  \n",
       "41                              0.050498  \n",
       "42                              0.111181  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['NVDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sentiments_vs_metric_as_mlr(stock_symbols, results, interval_days, metric):\n",
    "    \"\"\"\n",
    "    Fits multilinear regression of sentiment scores against either SMA or price difference.\n",
    "\n",
    "    Parameters:\n",
    "    - stock_symbols: List of stock symbols to process.\n",
    "    - results: Dictionary with stock data DataFrames.\n",
    "    - interval_days: The interval of days over which metrics are calculated.\n",
    "    - metric: Specify either 'sma' or 'price_diff' to choose which metric to plot.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing models and MSEs for each stock symbol.\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries to store linear models and MSEs\n",
    "    mlr_model = {}\n",
    "    mlr_mses = {}\n",
    "\n",
    "    for symbol in stock_symbols:\n",
    "        # Construct column names based on the actual interval_days and selected metric\n",
    "        news_sentiment_col = f'{symbol}_Balanced_Avg_News_Sentiment_{interval_days}d'\n",
    "        stock_sentiment_col = f'{symbol}_Balanced_Avg_Stock_Sentiment_{interval_days}d'\n",
    "        if metric == 'sma':\n",
    "            metric_col = f'{symbol}_SMA_{interval_days}d'\n",
    "        elif metric == 'price_diff':\n",
    "            metric_col = f'{symbol}_Price_Diff_{interval_days}d'\n",
    "        else:\n",
    "            print(f\"Unknown metric '{metric}'. Choose 'sma' or 'price_diff'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Check if the expected columns exist in the DataFrame for the current symbol\n",
    "        if (\n",
    "            symbol in results and \n",
    "            news_sentiment_col in results[symbol].columns and \n",
    "            stock_sentiment_col in results[symbol].columns and \n",
    "            metric_col in results[symbol].columns\n",
    "        ):\n",
    "            # Extract features (sentiment columns) and target (metric column)\n",
    "            X = results[symbol][[news_sentiment_col, stock_sentiment_col]].values\n",
    "            y = results[symbol][metric_col].values\n",
    "\n",
    "            # Fit a multilinear regression model\n",
    "            pipeline = Pipeline([\n",
    "                ('scale', StandardScaler()),\n",
    "                ('mlr', LinearRegression())\n",
    "            ])\n",
    "            pipeline.fit(X, y)\n",
    "            y_pred = pipeline.predict(X)\n",
    "\n",
    "            # Store the model and MSE\n",
    "            mlr_model[symbol] = pipeline\n",
    "            mlr_mses[symbol] = mse(y, y_pred)\n",
    "\n",
    "            print(f\"{symbol}: Model fitted. MSE = {mlr_mses[symbol]:.4f}\")\n",
    "        else:\n",
    "            print(f\"Required columns for {symbol} with interval {interval_days} days not found. Skipping.\")\n",
    "\n",
    "    return {'models': mlr_model, 'mse': mlr_mses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOG: Model fitted. MSE = 1456.2790\n",
      "MSFT: Model fitted. MSE = 6484.8479\n",
      "NVDA: Model fitted. MSE = 239.5404\n",
      "AMZN: Model fitted. MSE = 2878.2509\n",
      "AAPL: Model fitted. MSE = 2626.0585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'models': {'GOOG': Pipeline(steps=[('scale', StandardScaler()), ('mlr', LinearRegression())]),\n",
       "  'MSFT': Pipeline(steps=[('scale', StandardScaler()), ('mlr', LinearRegression())]),\n",
       "  'NVDA': Pipeline(steps=[('scale', StandardScaler()), ('mlr', LinearRegression())]),\n",
       "  'AMZN': Pipeline(steps=[('scale', StandardScaler()), ('mlr', LinearRegression())]),\n",
       "  'AAPL': Pipeline(steps=[('scale', StandardScaler()), ('mlr', LinearRegression())])},\n",
       " 'mse': {'GOOG': np.float64(1456.2790118454427),\n",
       "  'MSFT': np.float64(6484.847862521754),\n",
       "  'NVDA': np.float64(239.5404311643511),\n",
       "  'AMZN': np.float64(2878.250887770791),\n",
       "  'AAPL': np.float64(2626.0585347191563)}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_sentiments_vs_metric_as_mlr(stock_symbols, results, interval_days, 'sma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multilinear_regression(results, stock_symbol, interval_days, metric):\n",
    "    \"\"\"\n",
    "    Runs a multilinear regression of balanced average news and stock sentiment scores\n",
    "    against either SMA or price difference.\n",
    "\n",
    "    Parameters:\n",
    "    - results: Dictionary with stock data DataFrames.\n",
    "    - stock_symbol: The symbol of the stock to analyze.\n",
    "    - interval_days: The interval of days over which metrics are calculated.\n",
    "    - metric: Specify either 'sma' or 'price_diff' to choose which metric to analyze.\n",
    "    \"\"\"\n",
    "    # Define column names based on interval_days and selected metric\n",
    "    balanced_avg_news_sentiment_col = f'{stock_symbol}_Balanced_Avg_News_Sentiment_{interval_days}d'\n",
    "    balanced_avg_stock_sentiment_col = f'{stock_symbol}_Balanced_Avg_Stock_Sentiment_{interval_days}d'\n",
    "    if metric == 'sma':\n",
    "        metric_col = f'{stock_symbol}_SMA_{interval_days}d'\n",
    "    elif metric == 'price_diff':\n",
    "        metric_col = f'{stock_symbol}_Price_Diff_{interval_days}d'\n",
    "    else:\n",
    "        print(f\"Unknown metric '{metric}'. Choose 'sma' or 'price_diff'.\")\n",
    "        return\n",
    "\n",
    "    # Check if the required columns exist in the DataFrame\n",
    "    if stock_symbol in results and \\\n",
    "       balanced_avg_news_sentiment_col in results[stock_symbol].columns and \\\n",
    "       balanced_avg_stock_sentiment_col in results[stock_symbol].columns and \\\n",
    "       metric_col in results[stock_symbol].columns:\n",
    "        \n",
    "        # Extract predictor variables and the dependent variable\n",
    "        X_news = np.array(results[stock_symbol][balanced_avg_news_sentiment_col])\n",
    "        X_stock = np.array(results[stock_symbol][balanced_avg_stock_sentiment_col])\n",
    "        y_stats = np.array(results[stock_symbol][metric_col])\n",
    "        \n",
    "        # Combine predictors into a single 2D array\n",
    "        X_combined = np.column_stack((X_news, X_stock))\n",
    "        \n",
    "        # Add a constant to the predictors for the intercept\n",
    "        X_with_const = sm.add_constant(X_combined)\n",
    "\n",
    "        # Fit the OLS model\n",
    "        model_ols = sm.OLS(y_stats, X_with_const)\n",
    "        results_ols = model_ols.fit()\n",
    "\n",
    "        # Print the summary to see coefficients and other statistics\n",
    "        print(results_ols.summary())\n",
    "\n",
    "        # Get the confidence intervals for the coefficients\n",
    "        confidence_intervals = results_ols.conf_int(alpha=0.05)  # 95% CI by default\n",
    "        print(\"Confidence intervals:\\n\", confidence_intervals)\n",
    "    else:\n",
    "        print(f\"Required columns for {stock_symbol} with interval {interval_days} days and metric '{metric}' not found in results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.361\n",
      "Model:                            OLS   Adj. R-squared:                  0.347\n",
      "Method:                 Least Squares   F-statistic:                     25.66\n",
      "Date:                Sun, 17 Nov 2024   Prob (F-statistic):           1.45e-09\n",
      "Time:                        15:01:03   Log-Likelihood:                -503.42\n",
      "No. Observations:                  94   AIC:                             1013.\n",
      "Df Residuals:                      91   BIC:                             1020.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         88.6036      6.515     13.599      0.000      75.662     101.546\n",
      "x1          -464.4925     78.524     -5.915      0.000    -620.471    -308.515\n",
      "x2           259.2993    103.874      2.496      0.014      52.967     465.632\n",
      "==============================================================================\n",
      "Omnibus:                        0.022   Durbin-Watson:                   0.246\n",
      "Prob(Omnibus):                  0.989   Jarque-Bera (JB):                0.127\n",
      "Skew:                           0.032   Prob(JB):                        0.938\n",
      "Kurtosis:                       2.831   Cond. No.                         20.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Confidence intervals:\n",
      " [[  75.66158585  101.54554933]\n",
      " [-620.47058482 -308.51450212]\n",
      " [  52.96690254  465.63169699]]\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters\n",
    "stock_symbol = 'AAPL'\n",
    "interval_days = 14\n",
    "metric = 'sma'  \n",
    "\n",
    "# Run the multilinear regression\n",
    "run_multilinear_regression(results, stock_symbol, interval_days, metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
