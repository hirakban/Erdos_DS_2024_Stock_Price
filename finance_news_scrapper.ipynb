{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the `FinanceNewsScraper` Class\n",
    "\n",
    "The `FinanceNewsScraper` class is designed to scrape financial news articles from the business section of Google News based on a set of specified buzzwords and a given date range.\n",
    "\n",
    "- **Initialization (`__init__`)**: \n",
    "  - The scraper accepts two sets of buzzwords:\n",
    "    - **Must-have buzzwords**: Keywords that must appear in the article title or description.\n",
    "    - **Percentage-based buzzwords**: Keywords that need to match a certain percentage within the article.\n",
    "  - It also takes a `start_date`, `end_date`, and an interval for scraping in chunks (e.g., weekly).\n",
    "\n",
    "- **URL Construction (`construct_url`)**: \n",
    "  - This function builds a Google News RSS URL specifically for the business section, incorporating the provided buzzwords and date range.\n",
    "\n",
    "- **Fetching Data (`fetch_rss_feed`)**: \n",
    "  - This function retrieves the RSS feed using the constructed URL, retrying up to three times if errors are encountered.\n",
    "  - **Robust Retry Mechanism**:\n",
    "      - To ensure stable scraping even when there are network issues, the class includes a retry mechanism. It retries the process multiple times if it fails to retrieve the Yahoo Finance page, adding reliability to the data extraction process.\n",
    "\n",
    "\n",
    "- **Keyword Matching**:\n",
    "  - **Must-have buzzwords**: Ensures that at least one must-have buzzword appears in the article's title or description.\n",
    "  - **Percentage-based buzzwords**: Verifies that a minimum percentage of the provided buzzwords are present in the article.\n",
    "\n",
    "- **Article Parsing (`parse_articles`)**: \n",
    "  - This function parses the RSS feed and extracts relevant information such as the article title, URL, and publication date, but only for articles that match the buzzword criteria.\n",
    "\n",
    "- **Scraping (`scrape`)**: \n",
    "  - This method iterates through the specified date range, fetching and parsing articles in chunks as defined by the provided interval.\n",
    "\n",
    "- **Saving to CSV (`save_to_csv`)**: \n",
    "  - After scraping, the articles are saved to a CSV file using the `pandas` library for easy storage and further analysis.\n",
    "\n",
    "This class simplifies the process of scraping Google News for business-related articles based on keywords, while also offering functionality to save the results as a CSV file for later analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinanceNewsScraper:\n",
    "    def __init__(self, primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, interval):\n",
    "        \"\"\"\n",
    "        Initialize the scraper with two sets of buzzwords, start date, end date, and required percentage.\n",
    "        :param primary_buzzwords: List of buzzwords that must be present.\n",
    "        :param secondary_buzzwords: List of buzzwords to search for with percentage matching.\n",
    "        :param start_date: The start date (YYYY-MM-DD) for the articles.\n",
    "        :param end_date: The end date (YYYY-MM-DD) for the articles.\n",
    "        :param required_percentage: The percentage of percentage-based buzzwords that should be present (default 60%).\n",
    "        \"\"\"\n",
    "        self.primary_buzzwords = primary_buzzwords\n",
    "        self.secondary_buzzwords = secondary_buzzwords\n",
    "        self.start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        self.end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        self.required_percentage = required_percentage / 100  # Convert percentage to decimal for calculations\n",
    "        self.base_url = \"https://news.google.com/rss\"\n",
    "        self.interval = interval\n",
    "        self.max_retries = 3  # Number of retries in case of failure\n",
    "\n",
    "    def construct_url(self, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Construct the Google News RSS URL with all buzzwords and date range.\n",
    "        :return: The constructed URL.\n",
    "        \"\"\"\n",
    "        combined_buzzwords = self.primary_buzzwords + self.secondary_buzzwords\n",
    "        query = \" AND \".join(combined_buzzwords)  # Combine all buzzwords with 'AND' to ensure all words are present\n",
    "        formatted_query = query.replace(\" \", \"%20\")  # Format query for URL\n",
    "        \n",
    "        url = f\"{self.base_url}?q={formatted_query}+after:{start_date}+before:{end_date}&hl=en-US&gl=US&ceid=US:en\"\n",
    "        \n",
    "        return url\n",
    "\n",
    "    def fetch_rss_feed(self, start_date, end_date, max_retries=5, backoff_factor=2):\n",
    "        \"\"\"\n",
    "        Fetch the RSS feed from Google News for a given date range, with retries and exponential backoff to avoid 503 errors.\n",
    "        :param start_date: The start date for fetching articles.\n",
    "        :param end_date: The end date for fetching articles.\n",
    "        :param max_retries: Maximum number of retries if the request fails.\n",
    "        :param backoff_factor: Factor by which the wait time increases after each failure.\n",
    "        :return: BeautifulSoup object with the RSS feed content.\n",
    "        \"\"\"\n",
    "        rss_url = self.construct_url(start_date, end_date)\n",
    "        attempt = 0\n",
    "        delay = 5  # Start with an initial delay of 5 seconds\n",
    "\n",
    "        while attempt < max_retries:\n",
    "            try:\n",
    "                response = requests.get(rss_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    return BeautifulSoup(response.content, 'xml')  # Parsing as XML\n",
    "                else:\n",
    "                    print(f\"Failed to retrieve RSS feed with status code {response.status_code}. Retrying...\")\n",
    "\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Error fetching the RSS feed: {e}. Retrying...\")\n",
    "\n",
    "            # Apply the exponential backoff\n",
    "            attempt += 1\n",
    "            time.sleep(delay)\n",
    "            delay *= backoff_factor  # Increase the delay exponentially\n",
    "\n",
    "        print(\"Max retries exceeded. Could not fetch the RSS feed.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    def contains_any_primary_buzzwords(self, text):\n",
    "        \"\"\"\n",
    "        Check if any must-have buzzwords are present in the given text.\n",
    "        :param text: The text to search for must-have buzzwords (case-insensitive).\n",
    "        :return: True if at least one must-have buzzword is found, False otherwise.\n",
    "        \"\"\"\n",
    "        text = text.lower()\n",
    "        return any(buzzword.lower() in text for buzzword in self.primary_buzzwords)\n",
    "\n",
    "    def contains_percentage_of_buzzwords(self, text):\n",
    "        \"\"\"\n",
    "        Check if at least the required percentage of percentage-based buzzwords are present in the given text.\n",
    "        :param text: The text to search for percentage-based buzzwords (case-insensitive).\n",
    "        :return: True if the required percentage of percentage-based buzzwords are found, False otherwise.\n",
    "        \"\"\"\n",
    "        text = text.lower()\n",
    "        buzzwords_found = sum(1 for buzzword in self.secondary_buzzwords if buzzword.lower() in text)\n",
    "        required_count = math.ceil(len(self.secondary_buzzwords) * self.required_percentage)\n",
    "        \n",
    "        # The condition now checks if at least the required count of buzzwords is found\n",
    "        return buzzwords_found >= required_count\n",
    "\n",
    "    def parse_articles(self, soup):\n",
    "        \"\"\"\n",
    "        Parse the RSS feed and extract article information.\n",
    "        Only return articles where all must-have buzzwords and a percentage of percentage-based buzzwords are found.\n",
    "        :param soup: BeautifulSoup object of the RSS feed.\n",
    "        :return: List of dictionaries with article titles, URLs, and publication dates.\n",
    "        \"\"\"\n",
    "        articles = []\n",
    "        for item in soup.find_all('item'):\n",
    "            title = item.title.text\n",
    "            link = item.link.text\n",
    "            description = item.description.text if item.description else \"\"\n",
    "            pub_date = item.pubDate.text\n",
    "            pub_date = datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %Z')  # Format the date\n",
    "            \n",
    "            # Check if any must-have buzzwords are present in title or description\n",
    "            first_100_words = \" \".join(description.split()[:100])\n",
    "            if self.contains_any_primary_buzzwords(title) or self.contains_any_primary_buzzwords(first_100_words):\n",
    "                # Check if the required percentage of percentage-based buzzwords are present\n",
    "                if self.contains_percentage_of_buzzwords(title) or self.contains_percentage_of_buzzwords(first_100_words):\n",
    "                    articles.append({'title': title, 'url': link, 'date': pub_date})\n",
    "        return articles\n",
    "\n",
    "    def scrape(self):\n",
    "        \"\"\"\n",
    "        Scrape the RSS feed and extract articles that match both must-have and percentage-based buzzwords.\n",
    "        :return: List of articles (titles, URLs, and dates).\n",
    "        \"\"\"\n",
    "        all_articles = []\n",
    "        delta = timedelta(days=self.interval)  # Fetch in intervals (e.g., weekly)\n",
    "        current_start_date = self.start_date\n",
    "        print(f\"Fetching articles from {current_start_date.strftime('%Y-%m-%d')} to {self.end_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        # Loop through the date range with the specified interval\n",
    "        while current_start_date < self.end_date:\n",
    "            current_end_date = min(current_start_date + delta, self.end_date)\n",
    "\n",
    "            soup = self.fetch_rss_feed(current_start_date.strftime('%Y-%m-%d'),\n",
    "                                       current_end_date.strftime('%Y-%m-%d'))\n",
    "            if soup:\n",
    "                articles = self.parse_articles(soup)\n",
    "                all_articles.extend(articles)\n",
    "\n",
    "            current_start_date += delta  # Move to the next interval\n",
    "\n",
    "        if all_articles:\n",
    "            print(f\"Found {len(all_articles)} articles matching the criteria.\")\n",
    "        else:\n",
    "            print(\"No articles found matching the criteria.\")\n",
    "        return all_articles\n",
    "\n",
    "    def save_to_csv(articles, filename):\n",
    "        \"\"\"\n",
    "        Save the scraped articles to a CSV file using pandas.\n",
    "        :param articles: List of articles with title, URL, and date.\n",
    "        :param filename: The name of the CSV file (default is \"articles.csv\").\n",
    "        \"\"\"\n",
    "        # Convert the list of articles to a pandas DataFrame and drop duplicates in case there are any\n",
    "        df = pd.DataFrame(articles).drop_duplicates()\n",
    "        \n",
    "        # Save DataFrame to CSV\n",
    "        df.to_csv(filename, index=False, encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching articles from 2024-10-21 to 2024-10-22\n",
      "No articles found matching the criteria.\n"
     ]
    }
   ],
   "source": [
    "primary_buzzwords = [\"gas\",\"petrol\",\"fuel\",\"price\",\"oil\"]\n",
    "secondary_buzzwords = [\"israel\", \"gaza\", \"palestine\", \"conflict\", \"war\", \"hamas\", \n",
    "                       \"ukraine\", \"russia\"]  # List of buzzwords to search for\n",
    "start_date = '2024-10-21'\n",
    "end_date = '2024-10-22'  # End date\n",
    "required_percentage = 6  # required_percentage% of the secondary buzzwords should be in title or description\n",
    "interval = 1\n",
    "\n",
    "scraper_news = FinanceNewsScraper(primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, interval)\n",
    "articles_news = scraper_news.scrape()\n",
    "\n",
    "# Save the output as CSV files \n",
    "FinanceNewsScraper.save_to_csv(articles_news, \"google_news_geopolitical_energy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `FinanceNewsAPIScraper` Class Description\n",
    "\n",
    "The `FinanceNewsAPIScraper` class is designed to fetch, filter, and save news articles from NewsAPI based on specified buzzwords. Key functionalities:\n",
    "\n",
    "- **Initialization**: Takes in an API key, primary and secondary buzzwords, date range, and retry settings.\n",
    "- **Fetch News**: Sends API requests and retries if rate limits are hit.\n",
    "- **Filter**: Filters articles to ensure primary buzzwords are present, with a required percentage of secondary buzzwords.\n",
    "- **Display & Save**: Displays the filtered articles and provides an option to save them to a CSV file.\n",
    "\n",
    "### Key Methods:\n",
    "- `fetch_news()`\n",
    "- `filter_articles()`\n",
    "- `display_articles()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinanceNewsAPIScraper:\n",
    "    def __init__(self, api_key, primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, retry_after):\n",
    "        self.api_key = api_key\n",
    "        self.primary_buzzwords = primary_buzzwords\n",
    "        self.secondary_buzzwords = secondary_buzzwords\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.required_percentage = required_percentage / 100\n",
    "        self.base_url = 'https://newsapi.org/v2/everything'\n",
    "        self.retry_after = retry_after\n",
    "\n",
    "    def contains_any_primary_buzzwords(self, text):\n",
    "        text = text.lower()\n",
    "        return any(buzzword.lower() in text for buzzword in self.primary_buzzwords)\n",
    "\n",
    "    def contains_required_percentage_of_secondary_buzzwords(self, text):\n",
    "        text = text.lower()\n",
    "        buzzwords_found = sum(1 for buzzword in self.secondary_buzzwords if buzzword.lower() in text)\n",
    "        required_count = math.ceil(len(self.secondary_buzzwords) * self.required_percentage)\n",
    "        return buzzwords_found >= required_count\n",
    "\n",
    "    def fetch_news(self, retries=3):\n",
    "        params = {\n",
    "                'q': ' OR '.join(self.primary_buzzwords + self.secondary_buzzwords),\n",
    "                'apiKey': self.api_key,\n",
    "                'from': self.start_date,\n",
    "                'to': self.end_date,\n",
    "                'language': 'en',\n",
    "                'sortBy': 'relevancy'\n",
    "            }\n",
    "\n",
    "\n",
    "        attempt = 0\n",
    "        while attempt < retries:\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            elif response.status_code == 429:\n",
    "                print(f\"Rate limit exceeded. Retrying after {self.retry_after} seconds...\")\n",
    "                time.sleep(self.retry_after)\n",
    "            else:\n",
    "                print(f\"Failed to fetch news articles. Status code: {response.status_code}\")\n",
    "                return None\n",
    "            attempt += 1\n",
    "        print(\"Max retries exceeded. Could not fetch the news.\")\n",
    "        return None\n",
    "\n",
    "    def filter_articles(self, news_data):\n",
    "        filtered_articles = []\n",
    "        if news_data and 'articles' in news_data:\n",
    "            for article in news_data['articles']:\n",
    "                title = article['title']\n",
    "                description = article['description'] or \"\"\n",
    "                content = title + \" \" + description\n",
    "                if self.contains_any_primary_buzzwords(content) and self.contains_required_percentage_of_secondary_buzzwords(content):\n",
    "                    filtered_articles.append(article)\n",
    "        return filtered_articles\n",
    "\n",
    "    def display_articles(self, articles):\n",
    "        if articles:\n",
    "            for i, article in enumerate(articles, start=1):\n",
    "                print(f\"{i}. {article['title']} ({article['publishedAt']})\")\n",
    "        else:\n",
    "            print(\"No articles found.\")\n",
    "\n",
    "    def scrape_and_filter_news(self):\n",
    "        news_data = self.fetch_news()\n",
    "        if news_data:\n",
    "            filtered_articles = self.filter_articles(news_data)\n",
    "            self.display_articles(filtered_articles)\n",
    "            return filtered_articles  # Ensure filtered_articles is returned\n",
    "        else:\n",
    "            print(\"Failed to retrieve or filter articles.\")\n",
    "            return []\n",
    "\n",
    "    def save_to_csv(self, articles, filename):\n",
    "        if articles:\n",
    "            data = [{\n",
    "                'title': article['title'],\n",
    "                'publishedAt': article['publishedAt'],\n",
    "                'url': article['url']\n",
    "            } for article in articles]\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(filename, index=False, encoding='utf-8')\n",
    "            print(f\"Articles saved to {filename}\")\n",
    "        else:\n",
    "            print(\"No articles to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_keys = ['51f3c8bce6b1473e9537d03fe37815e3','5d7f3433c9404b6aaba5c5db771f2c79','25d106c70b3c4ff3af1fb174e0afc2ed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**News Focus:** `Geopoliticial conflicts`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_buzzwords = [\"israel\", \"gaza\", \"palestine\", \"conflict\", \"war\", \"hamas\", \n",
    "                       \"ukraine\", \"russia\",\"airstrike\",\"attack\", \"crisis\",\"oil\",\"prices\",\"nato\",\"invasion\"\n",
    "                       \"iran\",\"afghanistan\",\"china\",\"taiwan\",\"military\",\n",
    "                       \"indo-pacific\",\"south china sea\",\"market\",\"nuclear\",\"escalate\",\"zelensky\",\"putin\"]  # List of buzzwords to search for\n",
    "required_percentage = 6\n",
    "retry_after = 60\n",
    "start_date = '2024-09-23'\n",
    "end_date = '2024-10-22'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**News Focus:** `Climate events`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_buzzwords = [\"extreme weather\", \"climate crisis\", \"rising sea levels\", \"coastal erosion\", \"heatwaves\",\n",
    "    \"atmospheric rivers\", \"carbon emissions\",\"greenhouse gases\", \"renewable energy\", \"deforestation\", \"carbon footprint\",\n",
    "    \"sustainable development\", \"biodiversity loss\",\"hurricane\",\"tsunami\",\"floods\"]\n",
    " # List of buzzwords to search for\n",
    "required_percentage = 6\n",
    "retry_after = 60\n",
    "start_date = '2024-09-23'\n",
    "end_date = '2024-10-22'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**News Focus:** `Elections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_buzzwords = [\"trump\",\"kamala\",\"harris\",\"biden\",\"modi\",\"narendra\",\"xi\",\"putin\", \"election\", \n",
    "                       \"2024\",\"campaign\",\"vote\",\"voter\"]\n",
    " # List of buzzwords to search for\n",
    "required_percentage = 6\n",
    "retry_after = 60\n",
    "start_date = '2024-09-23'\n",
    "end_date = '2024-10-22'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**News Focus:** `Pandemics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_buzzwords = [\"pandemic\",\"epidemic\",\"covid\",\"corona\",\"covid\",\"bird-flu\", \"public health crisis\", \"outbreak\", \"quarantine\",\n",
    "                        \"lockdown\",\"infection\", \"epicenter\",\"virus\",\"bacteria\",\"vaccine\",\"epicenter\"]\n",
    " # List of buzzwords to search for\n",
    "required_percentage = 6\n",
    "retry_after = 60\n",
    "start_date = '2024-09-23'\n",
    "end_date = '2024-10-22'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**News Focus:** `Government Policies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_buzzwords = [\"tariffs\", \"sanctions\", \"subsidies\", \"regulations\", \"reforms\",\"taxation\", \"immigration\",\"trade\",\n",
    "                         \"defense\", \"cybersecurity\",\"privacy\", \"surveillance\", \"government\", \"monetary\",\n",
    "                        \"labor\", \"manufacturing\", \"exports\", \"imports\", \"automation\",\"health\", \"care\",\"housing\"] # List of buzzwords to search for\n",
    "               \n",
    "required_percentage = 6\n",
    "retry_after = 60\n",
    "start_date = '2024-09-23'\n",
    "end_date = '2024-10-22'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Industry Focus:** `Energy`\n",
    "\n",
    "**Timeline:** `One month`\n",
    "\n",
    "In the US the two biggest stocks in these industries are `ExxonMobil` (XOM) and `Chevron` (CVX)\n",
    "\n",
    "*Stock Focus*: `XOM`, `CVX`, `WFRD`, `VNOM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Mitch McConnell goes after Trump's trade policy: 'I'm not a tariff fan' (2024-09-24T21:06:42Z)\n",
      "Articles saved to news_api_energy_one_month_govt.csv\n"
     ]
    }
   ],
   "source": [
    "primary_buzzwords = [\"exxon\", \"xom\", \"chevron\", \"cvx\", \"viper\", \"vnom\", \"murphy\", \"mur\",\"gas\",\n",
    "                     \"petrol\",\"fuel\",\"price\",\"oil\",\"shell\",\"carbon\",\"hydrogen\",\"nuclear\",\"coal\",\"fossil\",\n",
    "                     \"energy\",\"smart grid\",\"power\"]\n",
    "scraper = FinanceNewsAPIScraper(api_keys[1], primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, retry_after)\n",
    "filtered_articles = scraper.scrape_and_filter_news()\n",
    "scraper.save_to_csv(filtered_articles, \"news_api_energy_one_month_govt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Industry Focus:** `Materials sector`\n",
    "\n",
    "**Timeline:** `One month`\n",
    "\n",
    "In the US the two biggest stocks in this industry are `Sherwin-Williams` (SHW) and `DuPont` (DD)\n",
    "\n",
    "*Stock Focus*: `SHW`, `DD`, `GOLD`, `RIO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Titan Submersible Hearings Spotlight Multiple Issues With Its Carbon Fiber Hull (2024-09-25T21:01:25Z)\n",
      "2. US bans new types of goods from China over allegations of forced labor (2024-10-02T18:46:00Z)\n",
      "3. ICE's $2 Million Contract With a Spyware Vendor Is Under White House Review (2024-10-21T19:03:22Z)\n",
      "4. 90-ton 3D printer to build world's biggest rocket (2024-10-22T18:00:00Z)\n",
      "5. Foxconn Building Nvidia Superchip Facility In Mexico (2024-10-09T01:25:00Z)\n",
      "Articles saved to news_api_materials_one_month_govt.csv\n"
     ]
    }
   ],
   "source": [
    "api_key = '5d7f3433c9404b6aaba5c5db771f2c79'  \n",
    "primary_buzzwords = [\"sherwin\", \"williams\", \"shw\", \"dupont\", \"barrick\", \"gold\", \"rio\",\"tinto\",\"steel\",\n",
    "                     \"copper\",\"aluminum\",\"chemicals\",\"minning\",\"recycling\",\"bio-based\",\"materials\",\"carbon\",\n",
    "                     \"building\",\"cement\"]\n",
    "scraper = FinanceNewsAPIScraper(api_keys[1], primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, retry_after)\n",
    "filtered_articles = scraper.scrape_and_filter_news()\n",
    "scraper.save_to_csv(filtered_articles, \"news_api_materials_one_month_govt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Industry Focus:** `Industrials sector`\n",
    "\n",
    "**Timeline:** `One month`\n",
    "\n",
    "In the US the two biggest stocks in this industry are `UPS` (UPS) and `Raytheon` (RTX)\n",
    "\n",
    "*Stock Focus*: `UPS`, `RTX`, `DAL`, `UAL`,`LMT`,`BA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. DJI sues the US Department of Defense for labeling it a ‘Chinese Military Company’ (2024-10-19T07:28:04Z)\n",
      "2. The West is trying to starve the wrong part of Russia's war machine, defense experts say (2024-10-20T11:23:01Z)\n",
      "3. Russia's defense industry has a massive labor shortage. Rules on what jobs women can do are part of the issue. (2024-10-05T10:43:02Z)\n",
      "4. Boeing suppliers fear long-term jobs hit from strike (2024-09-30T10:04:34Z)\n",
      "5. US laments 'disappointing' Swiss decision not to fully adopt latest EU sanctions against Russia (2024-10-18T16:45:28Z)\n",
      "6. Putin hosts a summit in a bid to show the West it can't keep Russia off the global stage (2024-10-21T05:55:04Z)\n",
      "7. Fears of automation are at the heart of the dockworkers strike (2024-10-02T14:22:50Z)\n",
      "8. Mindustry: Automation Tower Defense RTS with Deep Strategy and Modding (2024-09-29T17:01:32Z)\n",
      "9. Would Trump's tariffs trigger a global trade war? Experts weigh in. (2024-10-18T12:21:30Z)\n",
      "10. Mark Cuban says Trump's call for 200% tariffs on John Deere tractors is 'insane' and a 'good way to destroy a legendary American company' (2024-09-24T03:52:59Z)\n",
      "11. Key takeaways from the Walz-Vance vice presidential debate (2024-10-02T04:38:39Z)\n",
      "Articles saved to news_api_industrials_one_month_govt.csv\n"
     ]
    }
   ],
   "source": [
    "primary_buzzwords = [\"ups\", \"raytheon\", \"rtx\", \"delta\",\"airlines\",\"dal\",\"united\",\"ual\",\"lmt\",\"ba\",\"boeing\",\"machinery\"\n",
    "                     ,\"engineering\",\"automation\",\"defense\",\"aerospace\"]\n",
    "scraper = FinanceNewsAPIScraper(api_keys[1], primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, retry_after)\n",
    "filtered_articles = scraper.scrape_and_filter_news()\n",
    "scraper.save_to_csv(filtered_articles, \"news_api_industrials_one_month_govt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Industry Focus:** `Utilities sector`\n",
    "\n",
    "**Timeline:** `One month`\n",
    "\n",
    "In the US the two biggest stocks in this industry are `Duke energy` (DUK) and `Consolidated Edison` (ED)\n",
    "\n",
    "*Stock Focus*: `DUK`, `ED`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. US to unveil first of two decisions on more solar tariffs (2024-09-30T10:25:36Z)\n",
      "2. DJI sues the US Department of Defense for labeling it a ‘Chinese Military Company’ (2024-10-19T07:28:04Z)\n",
      "3. Mitch McConnell goes after Trump's trade policy: 'I'm not a tariff fan' (2024-09-24T21:06:42Z)\n",
      "4. Opinion: How to design a US data privacy law (2024-09-28T11:15:11Z)\n",
      "5. Trump is threatening tariffs on yet another business — and economists say it makes no sense (2024-09-25T08:00:02Z)\n",
      "6. Would Trump's tariffs trigger a global trade war? Experts weigh in. (2024-10-18T12:21:30Z)\n",
      "7. Scottish government: Assisted dying bill not in Holyrood's powers (2024-10-01T09:49:49Z)\n",
      "8. India Plans Laptop Import Curbs To Boost Local Manufacturing (2024-10-18T14:03:00Z)\n",
      "9. Britain targets Russian LNG sector with fresh shipping sanctions (2024-09-26T10:19:27Z)\n",
      "10. Hurricanes Helene’s Floods Swamped a Hospital, Highlighting Climate Threats to Health Care (2024-10-02T18:45:00Z)\n",
      "Articles saved to news_api_utilities_one_month_govt.vcsv\n"
     ]
    }
   ],
   "source": [
    "primary_buzzwords = [\"duke\", \"energy\", \"duk\", \"consolidated\", \"edison\", \"ed\", \"electricity\",\n",
    "                     \"water supply\",\"solar\",\"wind\",\"hydropower\",\"energy prices\",\"climate change\",\"public utilities\"]\n",
    "scraper = FinanceNewsAPIScraper(api_keys[1], primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, retry_after)\n",
    "filtered_articles = scraper.scrape_and_filter_news()\n",
    "scraper.save_to_csv(filtered_articles, \"news_api_utilities_one_month_govt.vcsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Industry Focus:** `Healthcare sector`\n",
    "\n",
    "**Timeline:** `One month`\n",
    "\n",
    "In the US the two biggest stocks in this industry are `UnitedHealth Group` (UNH) and `Johnson & Johnson` (JNJ)\n",
    "\n",
    "*Stock Focus*: `UNH`, `JNJ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Huntsville Hospital Health System terminates contract with United Healthcare (2024-10-10T19:29:22Z)\n",
      "2. FTC Sues Prescription Drug Middlemen for Artificially Inflating Insulin Prices (2024-09-23T10:58:56Z)\n",
      "3. Why conventional wisdom on health care is wrong (a primer) (2020) (2024-10-17T15:57:54Z)\n",
      "4. We left the US and moved to Mexico when I got pregnant 4 years ago. It's more affordable and our family is thriving. (2024-10-01T13:10:02Z)\n",
      "5. Why is US health care like this? (2024-10-01T20:40:32Z)\n",
      "6. Hurricanes Helene’s Floods Swamped a Hospital, Highlighting Climate Threats to Health Care (2024-10-02T18:45:00Z)\n",
      "7. Will AI tools revolutionize public health? Not if they continue following old patterns, researchers argue (2024-10-09T00:14:19Z)\n",
      "8. Novo Nordisk CEO blames drug 'middlemen' for high price of weight loss meds (2024-09-24T13:30:00Z)\n",
      "Articles saved to news_api_health_one_month_govt.csv\n"
     ]
    }
   ],
   "source": [
    "primary_buzzwords = [\"united health group\", \"health\", \"unh\", \"johnson & johnson\",\"jnj\",\"pharmaceuticals\"\n",
    "                     ,\"biotechnology\",\"drug\", \"clinical\",\"fda\"]\n",
    "scraper = FinanceNewsAPIScraper(api_keys[0], primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, retry_after)\n",
    "filtered_articles = scraper.scrape_and_filter_news()\n",
    "scraper.save_to_csv(filtered_articles, \"news_api_health_one_month_govt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Industry Focus:** `Financials sector`\n",
    "\n",
    "**Timeline:** `One month`\n",
    "\n",
    "In the US the two biggest stocks in this industry are `Berkshire Hathaway` (BRK.A and BRK.B) and `JPMorgan Chase` (JPM)\n",
    "\n",
    "*Stock Focus*: `BRK.A`, `BRK.BH`,`JPM`,`BAC`,`USB`, `pypl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. US economy grew at a solid 3% rate last quarter, government says in final estimate (2024-09-26T12:48:44Z)\n",
      "Articles saved to news_api_finance_one_month_govt.csv\n"
     ]
    }
   ],
   "source": [
    "primary_buzzwords = [\"berkshire\",\"hathaway\",\"jp morgan\",\"j.p. morgan\",\"chase\",\"bank\",\"of america\",\n",
    "                     \"brk.a\",\"brk.b\",\"bac\",\"usb\",\"paypal\",\"pypl\",\"stock\",\"interest rates\",\"inflation\",\n",
    "                     \"bonds\",\"capital\",\"investment\"]\n",
    "scraper = FinanceNewsAPIScraper(api_keys[1], primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, retry_after)\n",
    "filtered_articles = scraper.scrape_and_filter_news()\n",
    "scraper.save_to_csv(filtered_articles, \"news_api_finance_one_month_govt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Industry Focus:** `Consumers sector`\n",
    "\n",
    "**Timeline:** `One month`\n",
    "\n",
    "In the US the biggest stocks in this industry are `Coca-Cola` (KO), `Procter & Gamble` (PG), `Amazon` (AMZN), `Tesla` (TSLA) and McDonald's` (MCD)\n",
    "\n",
    "*Stock Focus*: `KO`, `PG`, `AMZN`, `MCD`, `TSLA`,`TM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. DJI sues the US Department of Defense for labeling it a ‘Chinese Military Company’ (2024-10-19T07:28:04Z)\n",
      "2. EU hits China with tariffs in electric car sales battle (2024-10-04T09:43:35Z)\n",
      "3. Findlay calls on Swinney to ditch National Care Service plans (2024-10-03T12:45:20Z)\n",
      "4. Scottish government: Assisted dying bill not in Holyrood's powers (2024-10-01T09:49:49Z)\n",
      "5. Opinion: How to design a US data privacy law (2024-09-28T11:15:11Z)\n",
      "6. 'Room for negotiation' on national care service plan - Gray (2024-09-29T10:51:54Z)\n",
      "Articles saved to news_api_consumers_one_month_govt.csv\n"
     ]
    }
   ],
   "source": [
    "primary_buzzwords = [\"coca-cola\",\"ko\",\"procter & gamble\",\"pg\",\"amazon\",\"macdonald's\",\"amzn\"\n",
    "                     ,\"mcd\",\"retail\",\"supply chain\",\"household\"\n",
    "                     ,\"automobile\",\"tesla\",\"tsla\",\"toyota\",\"tm\",\"vehicles\",\"car\"\n",
    "                     ,\"ev\",\"electric\"]\n",
    "scraper = FinanceNewsAPIScraper(api_keys[1], primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, retry_after)\n",
    "filtered_articles = scraper.scrape_and_filter_news()\n",
    "scraper.save_to_csv(filtered_articles, \"news_api_consumers_one_month_govt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Industry Focus:** `IT sector`\n",
    "\n",
    "**Timeline:** `One month`\n",
    "\n",
    "In the US the biggest stocks in this industry are `Apple` (AAPL), and `Microsoft` (MSFT)\n",
    "*Stock Focus*: `AAPL`, `MSFT`, `QCOM`, `NVDA`, `CRWD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No articles found.\n",
      "No articles to save.\n"
     ]
    }
   ],
   "source": [
    "primary_buzzwords = [\"crowd strike holdings\",\"crwd\",\"apple\",\"aapl\",\"microsoft\",\"msft\",\n",
    "                     \"qualcomm\",\"qcom\", \"nvidia\",\"nvda\", \"it\",\"information\",\"technology\",\"cybersecurity\"\n",
    "                     ,\"semiconductors\",\"ai\",\"artificial\"]\n",
    "scraper = FinanceNewsAPIScraper(api_keys[1], primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, retry_after)\n",
    "filtered_articles = scraper.scrape_and_filter_news()\n",
    "scraper.save_to_csv(filtered_articles, \"news_api_it_one_month_govt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Industry Focus:** `Communication services sector`\n",
    "\n",
    "**Timeline:** `One month`\n",
    "\n",
    "In the US the biggest stocks in this industry are `Facebook` (FB), and `Alphabet` (GOOG)\n",
    "*Stock Focus*: `FB`, `GOOG`, `WBD`, `NFLX`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Findlay calls on Swinney to ditch National Care Service plans (2024-10-03T12:45:20Z)\n",
      "2. Russia's defense industry has a massive labor shortage. Rules on what jobs women can do are part of the issue. (2024-10-05T10:43:02Z)\n",
      "3. Scottish government: Assisted dying bill not in Holyrood's powers (2024-10-01T09:49:49Z)\n",
      "Articles saved to news_api_communication_one_month_govt.csv\n"
     ]
    }
   ],
   "source": [
    "primary_buzzwords = [\"facebook\",\"meta\",\"fb\",\"alphabet\",\"goog\",\"warner bros\",\"wbd\",\"netflix\",\"nflx\"\n",
    "                     ,\"broadband\",\"5g\",\"media\",\"ott\",\"television\",\"streaming\",\"platforms\",\"film\"\n",
    "                     ,\"movie\",\"industry\"]\n",
    "scraper = FinanceNewsAPIScraper(api_keys[1], primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, retry_after)\n",
    "filtered_articles = scraper.scrape_and_filter_news()\n",
    "scraper.save_to_csv(filtered_articles, \"news_api_communication_one_month_govt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Industry Focus:** `Real estate sector`\n",
    "\n",
    "**Timeline:** `One month`\n",
    "\n",
    "In the US the biggest stocks in this industry are `American Tower` (AMT), and `Simon Property Group` (SPG)\n",
    "*Stock Focus*: `AMT`, `SPG`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Is the Dockworkers Union a Corporate Tool? (2024-10-04T22:30:01Z)\n",
      "2. How Racist Policies Destroyed Public Housing and Created the American Suburbs (2024-09-25T08:55:27Z)\n",
      "Articles saved to news_api_realestate_one_month_govt.csv\n"
     ]
    }
   ],
   "source": [
    "primary_buzzwords = [\"american tower\",\"amt\",\"simon property group\",\"spg\",\"real\",\"estate\",\"commercial\"\n",
    "                     ,\"residential\",\"property\",\"housing\",\"rental\",\"home\",\"prices\",\"mortgage\",\"land\"\n",
    "                     \"bubble\",\"loan\",\"urban\",\"planning\"]\n",
    "scraper = FinanceNewsAPIScraper(api_keys[1], primary_buzzwords, secondary_buzzwords, start_date, end_date, required_percentage, retry_after)\n",
    "filtered_articles = scraper.scrape_and_filter_news()\n",
    "scraper.save_to_csv(filtered_articles, \"news_api_realestate_one_month_govt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
